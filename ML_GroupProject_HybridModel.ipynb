{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_pickle('data/df_movies_cleaned.pkl')\n",
    "df_ratings = pd.read_pickle('data/df_ratings_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Rating Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    166444.000000\n",
      "mean        149.288073\n",
      "std         248.021364\n",
      "min          20.000000\n",
      "25%          35.000000\n",
      "50%          69.000000\n",
      "75%         158.000000\n",
      "max       18276.000000\n",
      "Name: count, dtype: float64\n",
      "count    45028.000000\n",
      "mean       551.836724\n",
      "std       2869.798512\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          8.000000\n",
      "75%         68.000000\n",
      "max      82895.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ratings_per_user = df_ratings[\"userId\"].value_counts()\n",
    "ratings_per_movie = df_ratings[\"movieId\"].value_counts()\n",
    "\n",
    "print(ratings_per_user.describe())\n",
    "print(ratings_per_movie.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    166317.000000\n",
      "mean        148.571679\n",
      "std         239.911174\n",
      "min          20.000000\n",
      "25%          35.000000\n",
      "50%          69.000000\n",
      "75%         158.000000\n",
      "max        9503.000000\n",
      "dtype: float64\n",
      "count    16705.000000\n",
      "mean      1479.197606\n",
      "std       4563.793861\n",
      "min         20.000000\n",
      "25%         48.000000\n",
      "50%        163.000000\n",
      "75%        794.000000\n",
      "max      82877.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ratings_count_per_movie = df_ratings.groupby('movieId').size()\n",
    "movies_with_enough_ratings = ratings_count_per_movie[ratings_count_per_movie >= 20].index\n",
    "prelim_df_ratings_filtered = df_ratings[df_ratings['movieId'].isin(movies_with_enough_ratings)]\n",
    "\n",
    "ratings_count_per_user = prelim_df_ratings_filtered.groupby('userId').size()\n",
    "users_with_enough_ratings = ratings_count_per_user[ratings_count_per_user >= 20].index\n",
    "df_ratings_filtered_final = prelim_df_ratings_filtered[prelim_df_ratings_filtered['userId'].isin(users_with_enough_ratings)]\n",
    "\n",
    "final_ratings_count_per_movie = df_ratings_filtered_final.groupby('movieId').size()\n",
    "final_movies_with_enough_ratings = final_ratings_count_per_movie[final_ratings_count_per_movie >= 20].index\n",
    "df_ratings_filtered_final = df_ratings_filtered_final[df_ratings_filtered_final['movieId'].isin(final_movies_with_enough_ratings)]\n",
    "\n",
    "print(df_ratings_filtered_final.groupby('userId').size().describe())\n",
    "print(df_ratings_filtered_final.groupby('movieId').size().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Textual Feature - Combined Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['combined_text'] = df_merged.apply(lambda row: ' '.join([\n",
    "    ' '.join(row['genre_extracted']), \n",
    "    ' '.join(row['actors']), \n",
    "    ' '.join(row['keywords_extracted']), \n",
    "    row['overview'], \n",
    "    ' '.join(row['production_company_extracted'])\n",
    "]).lower(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combined_text feature aggregates critical textual metadata from genres, actors, keywords, and movie descriptions into a single comprehensive descriptor for each movie. This aggregation captures the essence of a movie’s content, thematic elements, and appeal, which is crucial for content-based filtering. By synthesizing this information, the recommender system can identify and suggest movies with similar thematic and content attributes, enhancing personalization and user engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining df_ratings and df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.merge(df_ratings, df_merged, on='movieId', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Rating Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision to set a threshold of 20 ratings for each movie before including it in the item-based recommender system is strategic, with the goal of ensuring the reliability and validity of the generated recommendations. This threshold acts as a quality control measure, weeding out movies with sparse feedback that could otherwise result in skewed or less confident recommendations due to insufficient user data. By setting this minimum, the system focuses on movies with a high level of viewer engagement, allowing recommendations to be built on a solid foundation of user feedback. This approach improves the system's ability to deliver accurate, trustworthy recommendations based on broad consensus rather than outliers or minimal feedback, resulting in a better user experience and increased overall credibility for the recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: (24669326, 19)\n",
      "Filtered dataset size: (24548423, 19)\n"
     ]
    }
   ],
   "source": [
    "ratings_per_movie = df_combined.groupby('movieId').size()\n",
    "\n",
    "movies_with_enough_ratings = ratings_per_movie[ratings_per_movie >= 20].index\n",
    "\n",
    "df_item_modeling = df_combined[df_combined['movieId'].isin(movies_with_enough_ratings)]\n",
    "\n",
    "print(f\"Original dataset size: {df_combined.shape}\")\n",
    "print(f\"Filtered dataset size: {df_item_modeling.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the filtered dataset, df_item_modeling, now comprising 24,528,484 rows out of the original 24,639,944, it's evident that the vast majority of the data meets the threshold of having at least 20 ratings per movie. This minimal reduction in dataset size suggests that most movies in the dataset have a sufficient number of ratings, indicating robust user engagement across a wide range of movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grouping Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_item_modeling.groupby('movieId', as_index=False).agg({\n",
    "    'title': 'first',\n",
    "    'combined_text': 'first', \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>animation comedy family tom hanks tim allen do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>adventure fantasy family robin williams jonath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>romance comedy walter matthau jack lemmon ann-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>comedy drama romance whitney houston angela ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>comedy steve martin diane keaton martin short ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16122</th>\n",
       "      <td>173941</td>\n",
       "      <td>Atomic Blonde</td>\n",
       "      <td>action thriller charlize theron james mcavoy s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16123</th>\n",
       "      <td>174053</td>\n",
       "      <td>Black Mirror: White Christmas</td>\n",
       "      <td>drama horror mystery science fiction thriller ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16124</th>\n",
       "      <td>174055</td>\n",
       "      <td>Dunkirk</td>\n",
       "      <td>action drama history thriller war fionn whiteh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16125</th>\n",
       "      <td>174371</td>\n",
       "      <td>Once Upon a Time in Venice</td>\n",
       "      <td>action comedy thriller bruce willis jason momo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16126</th>\n",
       "      <td>174585</td>\n",
       "      <td>Transformers: The Last Knight</td>\n",
       "      <td>action science fiction thriller adventure mark...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16127 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                          title  \\\n",
       "0            1                      Toy Story   \n",
       "1            2                        Jumanji   \n",
       "2            3               Grumpier Old Men   \n",
       "3            4              Waiting to Exhale   \n",
       "4            5    Father of the Bride Part II   \n",
       "...        ...                            ...   \n",
       "16122   173941                  Atomic Blonde   \n",
       "16123   174053  Black Mirror: White Christmas   \n",
       "16124   174055                        Dunkirk   \n",
       "16125   174371     Once Upon a Time in Venice   \n",
       "16126   174585  Transformers: The Last Knight   \n",
       "\n",
       "                                           combined_text  \n",
       "0      animation comedy family tom hanks tim allen do...  \n",
       "1      adventure fantasy family robin williams jonath...  \n",
       "2      romance comedy walter matthau jack lemmon ann-...  \n",
       "3      comedy drama romance whitney houston angela ba...  \n",
       "4      comedy steve martin diane keaton martin short ...  \n",
       "...                                                  ...  \n",
       "16122  action thriller charlize theron james mcavoy s...  \n",
       "16123  drama horror mystery science fiction thriller ...  \n",
       "16124  action drama history thriller war fionn whiteh...  \n",
       "16125  action comedy thriller bruce willis jason momo...  \n",
       "16126  action science fiction thriller adventure mark...  \n",
       "\n",
       "[16127 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content-Based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing 'combined_text' feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df_grouped['combined_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing the combined_text using TF-IDF transforms qualitative textual information into quantitative vectors, facilitating the measurement of content similarity between movies. This numerical representation allows for sophisticated algorithms to compute similarities based on thematic elements, narrative structures, and genre affiliations. For our movie recommender system, this means being able to recommend movies that are contextually and thematically aligned with a user’s preferences, enhancing the discovery of relevant and appealing content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaseLine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "class SimplifiedContentRecommender:\n",
    "    def __init__(self, movies_df, tfidf_matrix, k=100):\n",
    "        self.movies_df = movies_df.copy()\n",
    "        self.movies_df['movieId'] = self.movies_df['movieId'].astype(str)\n",
    "        self.movie_id_to_index = {movie_id: i for i, movie_id in enumerate(self.movies_df['movieId'])}\n",
    "        self.tfidf_matrix = tfidf_matrix \n",
    "        self.similarity_matrix = cosine_similarity(self.tfidf_matrix)\n",
    "\n",
    "    def recommend(self, movie_id, top_n=10):\n",
    "        movie_id = str(movie_id)\n",
    "        if movie_id not in self.movie_id_to_index:\n",
    "            print(f\"Movie ID {movie_id} not found in the dataset.\")\n",
    "            return []\n",
    "        \n",
    "        movie_index = self.movie_id_to_index[movie_id]\n",
    "        similarity_scores = self.similarity_matrix[movie_index]\n",
    "        top_k_indices = np.argsort(similarity_scores)[::-1][1:top_n+1]\n",
    "        recommendations = self.movies_df.iloc[top_k_indices].copy()\n",
    "        recommendations['cosine_similarity'] = similarity_scores[top_k_indices]\n",
    "        \n",
    "        return recommendations.sort_values('cosine_similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      movieId            title  cosine_similarity\n",
      "2874     3114      Toy Story 2           0.498092\n",
      "12007   78499      Toy Story 3           0.417211\n",
      "1722     1920   Small Soldiers           0.216866\n",
      "2048     2253             Toys           0.186901\n",
      "7112     7987            Dolls           0.180138\n",
      "12339   83219  The Pixar Story           0.178043\n",
      "1552     1707     Home Alone 3           0.163932\n",
      "1793     1991     Child's Play           0.151260\n",
      "9645    46948    Monster House           0.144818\n",
      "1795     1993   Child's Play 3           0.143198\n"
     ]
    }
   ],
   "source": [
    "recommender_base = SimplifiedContentRecommender(df_grouped, tfidf_matrix, k=100)\n",
    "recommendations_base = recommender_base.recommend('1', top_n=10)  \n",
    "print(recommendations_base[['movieId', 'title', 'cosine_similarity']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, the sampling technique used is to calculate a statistically significant sample size in order to estimate the proportion of movies rated 4.0 or higher in a dataset. This decision is based on a specific confidence level (95%) and margin of error (5%), with the goal of obtaining precise and reliable inferences about the population's characteristics from a sample of data. The method used employs a standard formula that includes the Z-score associated with the desired confidence level and the estimated proportion of interest, ensuring that the sample size is sufficient to accurately reflect the population. This technique is critical for designing studies or analyses that require accurate estimations of population parameters for decision-making or hypothesis testing, as it minimizes potential biases and errors caused by small or arbitrarily chosen sample sizes. By rigorously determining the required sample size, the approach improves the credibility and validity of the findings derived from the sample data, making it a cornerstone of statistical analysis and research methodologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size: 385\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import math\n",
    "\n",
    "def calculate_sample_size(confidence_level, margin_of_error, proportion):\n",
    "    z_score = abs(scipy.stats.norm.ppf((1 - confidence_level) / 2))\n",
    "    sample_size = math.ceil((z_score ** 2 * proportion * (1 - proportion)) / (margin_of_error ** 2))\n",
    "    return sample_size\n",
    "\n",
    "confidence_level = 0.95\n",
    "margin_of_error = 0.05\n",
    "\n",
    "proportion_higher_ratings = df_ratings[df_ratings['rating'] >= 4.0].shape[0] / df_ratings.shape[0]\n",
    "required_sample_size = calculate_sample_size(confidence_level, margin_of_error, proportion_higher_ratings)\n",
    "print(f\"Required sample size: {required_sample_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_movie_ids = np.random.choice(df_grouped['movieId'].unique(), size=required_sample_size, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_movie(movie_id, df_ratings, recommender, top_n=10):\n",
    "    \"\"\"Evaluate a single movie for the recommender system, adjusted for actual user ratings.\"\"\"\n",
    "    recommendations = recommender.recommend(str(movie_id), top_n=top_n)\n",
    "    if recommendations.empty:\n",
    "        return np.array([]), None  # Use None to indicate no data for calculation\n",
    "\n",
    "    recommended_ids = recommendations['movieId'].astype(str).tolist()\n",
    "    # Filter ratings to those that match the recommended movie IDs\n",
    "    matching_ratings = df_ratings[df_ratings['movieId'].astype(str).isin(recommended_ids)]\n",
    "    \n",
    "    # Calculate hit rate only for recommended movies that have been rated\n",
    "    hit_rate = (matching_ratings['rating'] >= 4.0).mean() if not matching_ratings.empty else None\n",
    "\n",
    "    return np.array(matching_ratings['rating']), hit_rate\n",
    "\n",
    "def evaluate_recommender(df_ratings, recommender, sample_movie_ids, top_n=10, threshold=4.0):\n",
    "    \"\"\"Evaluate the recommender system using sampled movie IDs, including adjusted hit rate.\"\"\"\n",
    "    all_ratings, hit_rates = [], []\n",
    "\n",
    "    for movie_id in sample_movie_ids:\n",
    "        movie_ratings, hit_rate = evaluate_movie(movie_id, df_ratings, recommender, top_n=top_n)\n",
    "        if movie_ratings.size > 0:\n",
    "            all_ratings.extend(movie_ratings)\n",
    "        if hit_rate is not None:\n",
    "            hit_rates.append(hit_rate)\n",
    "    \n",
    "    all_ratings = np.array(all_ratings)\n",
    "    # Adjust calculations to handle potential None values in hit_rates\n",
    "    if len(all_ratings) > 0:\n",
    "        mae = np.mean(np.abs(all_ratings - 5))\n",
    "        mse = np.mean((all_ratings - 5) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        precision = np.sum(all_ratings >= threshold) / len(all_ratings)\n",
    "    else:\n",
    "        mae, mse, rmse, precision = 0, 0, 0, 0\n",
    "\n",
    "    avg_hit_rate = np.mean(hit_rates) if hit_rates else None  # Use None or a placeholder if no hit rates available\n",
    "\n",
    "    print(f\"Sample Size: {len(sample_movie_ids)}\")\n",
    "    # Adjust the print statement to handle None value for avg_hit_rate\n",
    "    print(f\"MAE: {mae:.4f}\\nMSE: {mse:.4f}\\nRMSE: {rmse:.4f}\\nPrecision: {precision:.4f}\\nAverage Hit Rate: {avg_hit_rate if avg_hit_rate is not None else 'N/A'}\")\n",
    "\n",
    "    return mae, mse, rmse, precision, avg_hit_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Item-based Collaborative Filtering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1235500 entries, 14910339 to 23314789\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count    Dtype         \n",
      "---  ------            --------------    -----         \n",
      " 0   userId            1235500 non-null  int64         \n",
      " 1   movieId           1235500 non-null  int64         \n",
      " 2   rating            1235500 non-null  Float64       \n",
      " 3   timestamp         1235500 non-null  datetime64[ns]\n",
      " 4   user_mean_rating  1235500 non-null  Float64       \n",
      " 5   liked_by_user     1235500 non-null  boolean       \n",
      "dtypes: Float64(2), boolean(1), datetime64[ns](1), int64(2)\n",
      "memory usage: 61.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_ratings_subset = df_ratings_filtered_final.sample(frac=0.05, random_state=42)\n",
    "df_ratings_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9130  0.9133  0.9135  0.9132  0.9129  0.9132  0.0002  \n",
      "MAE (testset)     0.7031  0.7028  0.7036  0.7036  0.7034  0.7033  0.0003  \n",
      "Fit time          9.91    9.58    10.30   9.77    9.89    9.89    0.24    \n",
      "Test time         1.11    1.07    1.12    1.41    1.33    1.21    0.14    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.91303477, 0.91332888, 0.91352622, 0.91320278, 0.91292555]),\n",
       " 'test_mae': array([0.70313489, 0.7028378 , 0.70359434, 0.70358235, 0.70335566]),\n",
       " 'fit_time': (9.909661293029785,\n",
       "  9.575968027114868,\n",
       "  10.30473780632019,\n",
       "  9.768281936645508,\n",
       "  9.891952991485596),\n",
       " 'test_time': (1.1085481643676758,\n",
       "  1.0685420036315918,\n",
       "  1.11647629737854,\n",
       "  1.4074289798736572,\n",
       "  1.3325819969177246)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "\n",
    "# Prepare the data for Surprise\n",
    "data = Dataset.load_from_df(df_ratings_subset[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Initialize the SVD algorithm\n",
    "svd = SVD()\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO GILIAN: Matrix geben lassen:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a mean Root Mean Sqaure Error of 0.95 approx which is more than good enough for our case. Let us now train on our dataset and arrive at predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x3ae7a0190>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=2, iid=150, r_ui=None, est=4.232214969794782, details={'was_impossible': False})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.predict(2, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score obtained:  0.9041399444694408\n",
      "Best parameters:  {'n_factors': 50, 'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.05}\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_factors': [50, 100],  # Number of factors\n",
    "    'n_epochs': [20],        # Number of iterations\n",
    "    'lr_all': [0.005, 0.01], # Learning rate\n",
    "    'reg_all': [0.02, 0.05]  # Regularization term\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "print(\"Best RMSE score obtained: \", gs.best_score['rmse'])\n",
    "print(\"Best parameters: \", gs.best_params['rmse'])\n",
    "\n",
    "optimized_svd = gs.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> intializing optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_svd = SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.05)\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5))  \n",
    "data = Dataset.load_from_df(df_ratings_subset[['userId', 'movieId', 'rating']], reader)\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x581b81290>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.973394488110365\n"
     ]
    }
   ],
   "source": [
    "prediction = optimized_svd.predict(uid=2, iid=3114)\n",
    "print(prediction.est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_model(movie_id, user_id, top_n, svd_model):\n",
    "    # Step 1: Get top N content-based recommendations\n",
    "    content_recs = recommender_base.recommend(movie_id, top_n)\n",
    "\n",
    "    content_recs['movieId'] = content_recs['movieId'].astype(int)\n",
    "\n",
    "    # Step 2: Apply SVD to predict ratings for the top N movies\n",
    "    content_recs['predicted_rating'] = content_recs['movieId'].apply(\n",
    "        lambda x: svd_model.predict(user_id, x).est\n",
    "    )\n",
    "    \n",
    "    # Step 3: Sort recommendations by predicted ratings, then by cosine similarity\n",
    "    final_recs = content_recs.sort_values(\n",
    "        by=['predicted_rating', 'cosine_similarity'], ascending=[False, False]\n",
    "    )\n",
    "    \n",
    "    final_recs = final_recs[['movieId', 'title', 'cosine_similarity', 'predicted_rating']]\n",
    "\n",
    "    return final_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12007</th>\n",
       "      <td>78499</td>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>0.417211</td>\n",
       "      <td>4.015826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>3114</td>\n",
       "      <td>Toy Story 2</td>\n",
       "      <td>0.498092</td>\n",
       "      <td>3.799826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12339</th>\n",
       "      <td>83219</td>\n",
       "      <td>The Pixar Story</td>\n",
       "      <td>0.178043</td>\n",
       "      <td>3.752612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>7987</td>\n",
       "      <td>Dolls</td>\n",
       "      <td>0.180138</td>\n",
       "      <td>3.623393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9645</th>\n",
       "      <td>46948</td>\n",
       "      <td>Monster House</td>\n",
       "      <td>0.144818</td>\n",
       "      <td>3.472350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>1920</td>\n",
       "      <td>Small Soldiers</td>\n",
       "      <td>0.216866</td>\n",
       "      <td>2.875540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>1991</td>\n",
       "      <td>Child's Play</td>\n",
       "      <td>0.151260</td>\n",
       "      <td>2.797392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>2253</td>\n",
       "      <td>Toys</td>\n",
       "      <td>0.186901</td>\n",
       "      <td>2.783716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>1993</td>\n",
       "      <td>Child's Play 3</td>\n",
       "      <td>0.143198</td>\n",
       "      <td>2.366231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>1707</td>\n",
       "      <td>Home Alone 3</td>\n",
       "      <td>0.163932</td>\n",
       "      <td>2.008950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId            title  cosine_similarity  predicted_rating\n",
       "12007    78499      Toy Story 3           0.417211          4.015826\n",
       "2874      3114      Toy Story 2           0.498092          3.799826\n",
       "12339    83219  The Pixar Story           0.178043          3.752612\n",
       "7112      7987            Dolls           0.180138          3.623393\n",
       "9645     46948    Monster House           0.144818          3.472350\n",
       "1722      1920   Small Soldiers           0.216866          2.875540\n",
       "1793      1991     Child's Play           0.151260          2.797392\n",
       "2048      2253             Toys           0.186901          2.783716\n",
       "1795      1993   Child's Play 3           0.143198          2.366231\n",
       "1552      1707     Home Alone 3           0.163932          2.008950"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_model(1, 1, 10, optimized_svd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
