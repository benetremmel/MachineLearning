{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import scipy.stats\n",
    "import math\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.read_pickle('data/df_movies_cleaned.pkl')\n",
    "df_ratings = pd.read_pickle('data/df_ratings_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Textual Feature - Combined Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['combined_text'] = df_merged.apply(lambda row: ' '.join([\n",
    "    ' '.join(row['genre_extracted']), \n",
    "    ' '.join(row['actors']), \n",
    "    ' '.join(row['keywords_extracted']), \n",
    "    row['overview'], \n",
    "    ' '.join(row['production_company_extracted'])\n",
    "]).lower(), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combined_text feature aggregates critical textual metadata from genres, actors, keywords, and movie descriptions into a single comprehensive descriptor for each movie. This aggregation captures the essence of a movie’s content, thematic elements, and appeal, which is crucial for content-based filtering. By synthesizing this information, the recommender system can identify and suggest movies with similar thematic and content attributes, enhancing personalization and user engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining df_ratings and df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.merge(df_ratings, df_merged, on='movieId', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Rating Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision to set a threshold of 20 ratings for each movie before including it in the item-based recommender system is strategic, with the goal of ensuring the reliability and validity of the generated recommendations. This threshold acts as a quality control measure, weeding out movies with sparse feedback that could otherwise result in skewed or less confident recommendations due to insufficient user data. By setting this minimum, the system focuses on movies with a high level of viewer engagement, allowing recommendations to be built on a solid foundation of user feedback. This approach improves the system's ability to deliver accurate, trustworthy recommendations based on broad consensus rather than outliers or minimal feedback, resulting in a better user experience and increased overall credibility for the recommender system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: (24669326, 19)\n",
      "Filtered dataset size: (24548423, 19)\n"
     ]
    }
   ],
   "source": [
    "ratings_per_movie = df_combined.groupby('movieId').size()\n",
    "\n",
    "movies_with_enough_ratings = ratings_per_movie[ratings_per_movie >= 20].index\n",
    "\n",
    "df_item_modeling = df_combined[df_combined['movieId'].isin(movies_with_enough_ratings)]\n",
    "\n",
    "print(f\"Original dataset size: {df_combined.shape}\")\n",
    "print(f\"Filtered dataset size: {df_item_modeling.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the filtered dataset, df_item_modeling, now comprising 24.548.423 rows out of the original 24.669.326, it's evident that the vast majority of the data meets the threshold of having at least 20 ratings per movie. This minimal reduction in dataset size suggests that most movies in the dataset have a sufficient number of ratings, indicating robust user engagement across a wide range of movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Grouping Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>animation comedy family tom hanks tim allen do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>adventure fantasy family robin williams jonath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>romance comedy walter matthau jack lemmon ann-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>comedy drama romance whitney houston angela ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>comedy steve martin diane keaton martin short ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                        title  \\\n",
       "0        1                    Toy Story   \n",
       "1        2                      Jumanji   \n",
       "2        3             Grumpier Old Men   \n",
       "3        4            Waiting to Exhale   \n",
       "4        5  Father of the Bride Part II   \n",
       "\n",
       "                                       combined_text  \n",
       "0  animation comedy family tom hanks tim allen do...  \n",
       "1  adventure fantasy family robin williams jonath...  \n",
       "2  romance comedy walter matthau jack lemmon ann-...  \n",
       "3  comedy drama romance whitney houston angela ba...  \n",
       "4  comedy steve martin diane keaton martin short ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped = df_item_modeling.groupby('movieId', as_index=False).agg({\n",
    "    'title': 'first',\n",
    "    'combined_text': 'first', \n",
    "})\n",
    "\n",
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-Based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorizing the combined_text using TF-IDF transforms qualitative textual information into quantitative vectors, facilitating the measurement of content similarity between movies. This numerical representation allows for sophisticated algorithms to compute similarities based on thematic elements, narrative structures, and genre affiliations. For our movie recommender system, this means being able to recommend movies that are contextually and thematically aligned with a user’s preferences, enhancing the discovery of relevant and appealing content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineContentRecommender:\n",
    "    def __init__(self, movies_df, k=100):\n",
    "        self.movies_df = movies_df.copy()\n",
    "        self.movies_df['movieId'] = self.movies_df['movieId'].astype(str)\n",
    "        self.movie_id_to_index = {movie_id: i for i, movie_id in enumerate(self.movies_df['movieId'])}\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "        self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(df_grouped['combined_text'])\n",
    "        self.similarity_matrix = cosine_similarity(self.tfidf_matrix)\n",
    "\n",
    "    def recommend(self, movie_id, top_n=10):\n",
    "        movie_id = str(movie_id)\n",
    "        if movie_id not in self.movie_id_to_index:\n",
    "            print(f\"Movie ID {movie_id} not found in the dataset.\")\n",
    "            return []\n",
    "        \n",
    "        movie_index = self.movie_id_to_index[movie_id]\n",
    "        similarity_scores = self.similarity_matrix[movie_index]\n",
    "        top_k_indices = np.argsort(similarity_scores)[::-1][1:top_n+1]\n",
    "        recommendations = self.movies_df.iloc[top_k_indices].copy()\n",
    "        recommendations['cosine_similarity'] = similarity_scores[top_k_indices]\n",
    "        \n",
    "        return recommendations.sort_values('cosine_similarity', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      movieId            title  cosine_similarity\n",
      "2874     3114      Toy Story 2           0.498092\n",
      "12007   78499      Toy Story 3           0.417211\n",
      "1722     1920   Small Soldiers           0.216866\n",
      "2048     2253             Toys           0.186901\n",
      "7112     7987            Dolls           0.180138\n",
      "12339   83219  The Pixar Story           0.178043\n",
      "1552     1707     Home Alone 3           0.163932\n",
      "1793     1991     Child's Play           0.151260\n",
      "9645    46948    Monster House           0.144818\n",
      "1795     1993   Child's Play 3           0.143198\n"
     ]
    }
   ],
   "source": [
    "recommender_base = BaselineContentRecommender(df_grouped, k=100)\n",
    "recommendations_base1 = recommender_base.recommend('1', top_n=10)  \n",
    "print(recommendations_base1[['movieId', 'title', 'cosine_similarity']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      movieId                             title  cosine_similarity\n",
      "8558    27884                         Word Wars           0.246909\n",
      "5855     6304                         Brainscan           0.164207\n",
      "9503    44731                        Stay Alive           0.144236\n",
      "14410  113889  Angry Video Game Nerd: The Movie           0.143081\n",
      "9366    42725                     Grandma's Boy           0.142472\n",
      "13344   97913                    Wreck-It Ralph           0.139435\n",
      "7422     8633              The Last Starfighter           0.132591\n",
      "15323  139847                         Chevalier           0.131599\n",
      "8295    26985                           Nirvana           0.130764\n",
      "14499  115534                             Ouija           0.127464\n"
     ]
    }
   ],
   "source": [
    "recommendations_base2 = recommender_base.recommend('2', top_n=10)  \n",
    "print(recommendations_base2[['movieId', 'title', 'cosine_similarity']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorized combined_text, which includes genres, keywords, and other descriptive elements, captures the thematic essence of films. This feature uses TF-IDF vectors to emphasize unique descriptors, allowing for the recommendation of movies with similar thematic and stylistic content. This is critical for a content-based system that relies on content similarities. This feature, as already used for the baseline-model, is critical and is shaping the foundation of our modeling approach. However, in order to advance the model we are increasing complexity by adding additonal features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "Feature engineering is an important step in the development of machine learning models, including recommender systems, because it involves extracting meaningful variables from raw data to improve model performance and accuracy. This process transforms complex and often unstructured information into structured, analytically useful formats, allowing models to uncover previously unknown patterns, relationships, and insights. In the context of developing a movie recommendation system, effective feature engineering ensures that the nuances of movie content, user preferences, and contextual factors are accurately captured and used. By carefully selecting, combining, and transforming data into features such as weighted scores, combined textual data, and sentiment analysis, developers can significantly improve the system's ability to provide personalized, relevant, and appealing movie recommendations. This not only improves user satisfaction and engagement, but it also strengthens the business case by increasing platform usage and retention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating           timestamp  user_mean_rating  \\\n",
      "0       1      110     1.0 2015-03-09 22:52:09          4.277778   \n",
      "1       1      147     4.5 2015-03-09 23:07:15          4.277778   \n",
      "2       1      858     5.0 2015-03-09 22:52:03          4.277778   \n",
      "3       1     1221     5.0 2015-03-09 22:52:26          4.277778   \n",
      "4       1     1246     5.0 2015-03-09 22:52:36          4.277778   \n",
      "\n",
      "   liked_by_user  weighted_score  average_rating  rating_count  \n",
      "0          False        4.000352        4.010725         62332  \n",
      "1           True        3.513227        3.581926          4559  \n",
      "2           True        4.319932        4.336495         52237  \n",
      "3           True        4.238059        4.261745         34163  \n",
      "4           True        3.888786        3.911582         25012  \n"
     ]
    }
   ],
   "source": [
    "movie_stats = df_ratings.groupby('movieId').agg(average_rating=('rating', 'mean'), rating_count=('rating', 'count')).reset_index()\n",
    "\n",
    "C = movie_stats['average_rating'].mean()\n",
    "m = movie_stats['rating_count'].quantile(0.90)\n",
    "\n",
    "def weighted_rating(x, m=m, C=C):\n",
    "    v = x['rating_count']  \n",
    "    R = x['average_rating'] \n",
    "    return (v/(v+m) * R) + (m/(m+v) * C)\n",
    "\n",
    "movie_stats['weighted_score'] = movie_stats.apply(weighted_rating, axis=1)\n",
    "\n",
    "df_ratings = df_ratings.merge(movie_stats[['movieId', 'weighted_score']], on='movieId', how='left')\n",
    "\n",
    "df_ratings = df_ratings.merge(movie_stats[['movieId', 'average_rating', 'rating_count']], on='movieId', how='left')\n",
    "\n",
    "print(df_ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted score combines a movie's average rating (vote_average) and the number of ratings (vote_count) it has received to provide a balanced metric that reflects both popularity and quality. This approach mitigates the bias towards movies with a high average rating but a low number of ratings, ensuring that the recommendations are not only high-quality but also broadly appreciated. For a movie recommender system, integrating the weighted score helps prioritize movies that have proven appeal, aligning recommendations with broader viewer satisfaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_year = datetime.datetime.now().year\n",
    "\n",
    "df_merged['movie_age'] = current_year - pd.to_datetime(df_merged['release_date']).dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the movie_age from the release date provides insight into the recency and potential cultural relevance of a movie. In the context of a movie recommender system, this allows for temporal filtering and trend analysis, enabling recommendations that cater to preferences for newer releases or classic films. Understanding movie age is essential for aligning recommendations with temporal viewing trends and user preferences for contemporary versus classic cinema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis of Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    except:\n",
    "        return None \n",
    "\n",
    "df_merged['sentiment_polarity'] = df_merged['overview'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing sentiment analysis on movie descriptions yields a sentiment_polarity score, offering a nuanced view of the emotional tone or mood conveyed by the movie's narrative. This feature is particularly important for recommending movies that match a user’s emotional preferences or current mood, adding an additional layer of personalization. By integrating sentiment analysis, your recommender system can differentiate movies not just by genre or content but also by the emotional experience they offer, enhancing user satisfaction and engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding new features to df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_aggregated = df_ratings.groupby('movieId', as_index=False).agg({\n",
    "    'weighted_score': 'mean'  \n",
    "})\n",
    "\n",
    "df_merged_aggregated = df_merged.groupby('movieId', as_index=False).agg({\n",
    "    'movie_age': 'mean', \n",
    "    'sentiment_polarity': 'mean'\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine df_ratings and df_merged to simplify our dataset, ensuring that each movieId is represented by a single set of features. By averaging weighted_score, movie_age, and sentiment_polarity, we capture each film's overall essence, reflecting collective attributes and sentiments. This preprocessing step converts our data into a unified df_grouped format, with each movie listed uniquely, simplifying subsequent analyses and modeling efforts. This approach not only consolidates our dataset to improve efficiency, but it also aligns with our goal of building a cohesive and analytically robust foundation for our recommendation system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_grouped.merge(df_ratings_aggregated, on='movieId', how='left')\n",
    "df_grouped = df_grouped.merge(df_merged_aggregated, on='movieId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>weighted_score</th>\n",
       "      <th>movie_age</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>animation comedy family tom hanks tim allen do...</td>\n",
       "      <td>3.884349</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.112121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>adventure fantasy family robin williams jonath...</td>\n",
       "      <td>3.227394</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-0.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>romance comedy walter matthau jack lemmon ann-...</td>\n",
       "      <td>3.141024</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.038889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>comedy drama romance whitney houston angela ba...</td>\n",
       "      <td>2.895332</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>comedy steve martin diane keaton martin short ...</td>\n",
       "      <td>3.061166</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16122</th>\n",
       "      <td>173941</td>\n",
       "      <td>Atomic Blonde</td>\n",
       "      <td>action thriller charlize theron james mcavoy s...</td>\n",
       "      <td>3.067902</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16123</th>\n",
       "      <td>174053</td>\n",
       "      <td>Black Mirror: White Christmas</td>\n",
       "      <td>drama horror mystery science fiction thriller ...</td>\n",
       "      <td>3.149876</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.067143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16124</th>\n",
       "      <td>174055</td>\n",
       "      <td>Dunkirk</td>\n",
       "      <td>action drama history thriller war fionn whiteh...</td>\n",
       "      <td>3.344268</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16125</th>\n",
       "      <td>174371</td>\n",
       "      <td>Once Upon a Time in Venice</td>\n",
       "      <td>action comedy thriller bruce willis jason momo...</td>\n",
       "      <td>3.026085</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16126</th>\n",
       "      <td>174585</td>\n",
       "      <td>Transformers: The Last Knight</td>\n",
       "      <td>action science fiction thriller adventure mark...</td>\n",
       "      <td>2.929636</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.104167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16127 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId                          title  \\\n",
       "0            1                      Toy Story   \n",
       "1            2                        Jumanji   \n",
       "2            3               Grumpier Old Men   \n",
       "3            4              Waiting to Exhale   \n",
       "4            5    Father of the Bride Part II   \n",
       "...        ...                            ...   \n",
       "16122   173941                  Atomic Blonde   \n",
       "16123   174053  Black Mirror: White Christmas   \n",
       "16124   174055                        Dunkirk   \n",
       "16125   174371     Once Upon a Time in Venice   \n",
       "16126   174585  Transformers: The Last Knight   \n",
       "\n",
       "                                           combined_text  weighted_score  \\\n",
       "0      animation comedy family tom hanks tim allen do...        3.884349   \n",
       "1      adventure fantasy family robin williams jonath...        3.227394   \n",
       "2      romance comedy walter matthau jack lemmon ann-...        3.141024   \n",
       "3      comedy drama romance whitney houston angela ba...        2.895332   \n",
       "4      comedy steve martin diane keaton martin short ...        3.061166   \n",
       "...                                                  ...             ...   \n",
       "16122  action thriller charlize theron james mcavoy s...        3.067902   \n",
       "16123  drama horror mystery science fiction thriller ...        3.149876   \n",
       "16124  action drama history thriller war fionn whiteh...        3.344268   \n",
       "16125  action comedy thriller bruce willis jason momo...        3.026085   \n",
       "16126  action science fiction thriller adventure mark...        2.929636   \n",
       "\n",
       "       movie_age  sentiment_polarity  \n",
       "0           29.0            0.112121  \n",
       "1           29.0           -0.218750  \n",
       "2           29.0            0.038889  \n",
       "3           29.0            0.600000  \n",
       "4           29.0            0.466667  \n",
       "...          ...                 ...  \n",
       "16122        7.0           -0.266667  \n",
       "16123       10.0            0.067143  \n",
       "16124        7.0            0.000000  \n",
       "16125        7.0            0.075000  \n",
       "16126        7.0           -0.104167  \n",
       "\n",
       "[16127 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When developing a content-based recommender system, the selection of features is critical to its success. The selected features - weighted_score, vectorized combined_text, movie_age, runtime, and sentiment_polarity - are critical for capturing the multifaceted nature of films and their reception by audiences.\n",
    "\n",
    "The weighted_score is critical for determining a movie's appeal, as it combines the average rating with the number of ratings to provide a balanced picture of its popularity and acceptance. This feature helps to reduce biases toward movies with less ratings, ensuring that recommendations are not only popular but also well-regarded.\n",
    "\n",
    "Movie_age incorporate personal preference and temporal relevance into the recommendation process.This feature allows the system to align recommendations with users' inclinations towards newer releases or classic films. These features provide additional layers of personalization, increasing user satisfaction by accommodating individual preferences for movie duration and novelty.\n",
    "\n",
    "Finally, sentiment_polarity provides information about the emotional tone of movie descriptions or reviews. This feature allows the system to recommend movies that match not only in content but also in mood, providing a more nuanced approach to similarity that goes beyond simple thematic alignment.\n",
    "\n",
    "Together, these features form a strong foundation for an item-based recommender system. By taking into account both content and key characteristics that influence viewer preferences, the system is better able to provide precise and satisfying movie recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedContentRecommender:\n",
    "    def __init__(self, movies_df, k=100):\n",
    "        self.movies_df = movies_df.copy()\n",
    "        self.movies_df['movieId'] = self.movies_df['movieId'].astype(str)\n",
    "        self.k = k\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "        self.tfidf_matrix = self.tfidf_vectorizer.fit_transform(self.movies_df['combined_text'])\n",
    "        self.similarity_matrix = cosine_similarity(self.tfidf_matrix)\n",
    "\n",
    "    def recommend(self, movie_id, top_n=10):\n",
    "        movie_id = str(movie_id)\n",
    "        if movie_id not in self.movies_df['movieId'].values:\n",
    "            print(f\"Movie ID {movie_id} not found in the dataset.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        movie_index = self.movies_df.index[self.movies_df['movieId'] == movie_id].tolist()[0]\n",
    "        similarity_scores = self.similarity_matrix[movie_index]\n",
    "        top_k_indices = np.argsort(similarity_scores)[::-1][1:self.k+1]\n",
    "        top_k_df = self.movies_df.iloc[top_k_indices].copy()\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        for feature in ['weighted_score', 'movie_age']:\n",
    "            if feature in top_k_df:\n",
    "                top_k_df[feature] = scaler.fit_transform(top_k_df[[feature]].values.reshape(-1, 1))\n",
    "\n",
    "        top_k_df['cosine_similarity'] = similarity_scores[top_k_indices]\n",
    "        top_k_df['combined_score'] = (\n",
    "            0.5 * top_k_df['cosine_similarity'] +\n",
    "            0.2 * top_k_df['weighted_score'] + \n",
    "            0.2 * top_k_df['sentiment_polarity'] +\n",
    "            0.1 * top_k_df['movie_age']\n",
    "        )\n",
    "        \n",
    "        return top_k_df.nlargest(top_n, 'combined_score')[['movieId', 'title', 'combined_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      movieId                  title  combined_score\n",
      "2874     3114            Toy Story 2        0.515295\n",
      "12007   78499            Toy Story 3        0.378643\n",
      "5555     5974    The Thief of Bagdad        0.355765\n",
      "1130     1230             Annie Hall        0.343074\n",
      "7112     7987                  Dolls        0.323468\n",
      "1143     1244              Manhattan        0.315088\n",
      "4019     4339     Von Ryan's Express        0.314689\n",
      "2142     2355           A Bug's Life        0.313347\n",
      "576       596              Pinocchio        0.308571\n",
      "1024     1103  Rebel Without a Cause        0.302987\n"
     ]
    }
   ],
   "source": [
    "recommender_advanced = AdvancedContentRecommender(df_grouped, k=100)\n",
    "recommendations_advanced1 = recommender_advanced.recommend('1', top_n=10)  \n",
    "print(recommendations_advanced1[['movieId', 'title', 'combined_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      movieId                                              title  \\\n",
      "1100     1197                                 The Princess Bride   \n",
      "5788     6232                                          Born Free   \n",
      "10217   54259                                           Stardust   \n",
      "1962     2161                              The NeverEnding Story   \n",
      "2865     3105                                         Awakenings   \n",
      "9304    41566  The Chronicles of Narnia: The Lion, the Witch ...   \n",
      "12067   79318                                      Winnebago Man   \n",
      "3901     4210                                          Manhunter   \n",
      "7422     8633                               The Last Starfighter   \n",
      "4768     5126                                  The Deadly Mantis   \n",
      "\n",
      "       combined_score  \n",
      "1100         0.394854  \n",
      "5788         0.308018  \n",
      "10217        0.303716  \n",
      "1962         0.300134  \n",
      "2865         0.278083  \n",
      "9304         0.267593  \n",
      "12067        0.250902  \n",
      "3901         0.249790  \n",
      "7422         0.243689  \n",
      "4768         0.238940  \n"
     ]
    }
   ],
   "source": [
    "recommendations_advanced2 = recommender_advanced.recommend('2', top_n=10)  \n",
    "print(recommendations_advanced2[['movieId', 'title', 'combined_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advanced model extends the baseline content recommender by including additional movie attributes—weighted_score, sentiment_polarity, and movie_age—as well as feature scaling for weighted_score and movie_age. This evolution enables the model to consider not only thematic content similarity, but also movie quality, viewer sentiment, and timeliness. By combining these various factors, the advanced model hopes to provide more nuanced and personalized recommendations. The strategic inclusion and scaling of these features improves the model's ability to better align recommendations with individual user preferences, potentially improving recommendation accuracy and user satisfaction over the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evalutation of content-based models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this scenario, the sampling technique used is to calculate a statistically significant sample size in order to estimate the proportion of movies rated 4.0 or higher in a dataset. This decision is based on a specific confidence level (95%) and margin of error (5%), with the goal of obtaining precise and reliable inferences about the population's characteristics from a sample of data. The method used employs a standard formula that includes the Z-score associated with the desired confidence level and the estimated proportion of interest, ensuring that the sample size is sufficient to accurately reflect the population. This technique is critical for designing studies or analyses that require accurate estimations of population parameters for decision-making or hypothesis testing, as it minimizes potential biases and errors caused by small or arbitrarily chosen sample sizes. By rigorously determining the required sample size, the approach improves the credibility and validity of the findings derived from the sample data, making it a cornerstone of statistical analysis and research methodologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required sample size: 385\n"
     ]
    }
   ],
   "source": [
    "def calculate_sample_size(confidence_level, margin_of_error, proportion):\n",
    "    z_score = abs(scipy.stats.norm.ppf((1 - confidence_level) / 2))\n",
    "    sample_size = math.ceil((z_score ** 2 * proportion * (1 - proportion)) / (margin_of_error ** 2))\n",
    "    return sample_size\n",
    "\n",
    "confidence_level = 0.95\n",
    "margin_of_error = 0.05\n",
    "\n",
    "proportion_higher_ratings = df_ratings[df_ratings['rating'] >= 4.0].shape[0] / df_ratings.shape[0]\n",
    "required_sample_size = calculate_sample_size(confidence_level, margin_of_error, proportion_higher_ratings)\n",
    "print(f\"Required sample size: {required_sample_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_movie_ids = np.random.choice(df_grouped['movieId'].unique(), size=required_sample_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df_ratings = df_ratings[df_ratings['movieId'].isin(sample_movie_ids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_movie(movie_id, df_ratings, recommender, top_n=10):\n",
    "    \"\"\"Evaluate a single movie for the recommender system, adjusted for actual user ratings.\"\"\"\n",
    "    recommendations = recommender.recommend(str(movie_id), top_n=top_n)\n",
    "    if recommendations.empty:\n",
    "        return np.array([]), None \n",
    "\n",
    "    recommended_ids = recommendations['movieId'].astype(str).tolist()\n",
    "    \n",
    "    matching_ratings = df_ratings[df_ratings['movieId'].astype(str).isin(recommended_ids)]\n",
    "    \n",
    "    hit_rate = (matching_ratings['rating'] >= 4.0).mean() if not matching_ratings.empty else None\n",
    "\n",
    "    return np.array(matching_ratings['rating']), hit_rate\n",
    "\n",
    "def evaluate_recommender(df_ratings, recommender, sample_movie_ids, top_n=10, threshold=4.0):\n",
    "    \"\"\"Evaluate the recommender system using sampled movie IDs, including adjusted hit rate.\"\"\"\n",
    "    all_ratings, hit_rates = [], []\n",
    "\n",
    "    for movie_id in sample_movie_ids:\n",
    "        movie_ratings, hit_rate = evaluate_movie(movie_id, df_ratings, recommender, top_n=top_n)\n",
    "        if movie_ratings.size > 0:\n",
    "            all_ratings.extend(movie_ratings)\n",
    "        if hit_rate is not None:\n",
    "            hit_rates.append(hit_rate)\n",
    "    \n",
    "    all_ratings = np.array(all_ratings)\n",
    "    if len(all_ratings) > 0:\n",
    "        mae = np.mean(np.abs(all_ratings - 5))\n",
    "        mse = np.mean((all_ratings - 5) ** 2)\n",
    "        rmse = np.sqrt(mse)\n",
    "        precision = np.sum(all_ratings >= threshold) / len(all_ratings)\n",
    "    else:\n",
    "        mae, mse, rmse, precision = 0, 0, 0, 0\n",
    "\n",
    "    avg_hit_rate = np.mean(hit_rates) if hit_rates else None  \n",
    "\n",
    "    print(f\"Sample Size: {len(sample_movie_ids)}\")\n",
    "    print(f\"MAE: {mae:.4f}\\nMSE: {mse:.4f}\\nRMSE: {rmse:.4f}\\nPrecision: {precision:.4f}\\nAverage Hit Rate: {avg_hit_rate if avg_hit_rate is not None else 'N/A'}\")\n",
    "\n",
    "    return mae, mse, rmse, precision, avg_hit_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of Baseline-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size: 385\n",
      "MAE: 1.4382\n",
      "MSE: 3.1930\n",
      "RMSE: 1.7869\n",
      "Precision: 0.5136\n",
      "Average Hit Rate: 0.46579011848169105\n"
     ]
    }
   ],
   "source": [
    "mae, mse, rmse, precision, avg_hit_rate = evaluate_recommender(df_ratings, recommender_base, sample_movie_ids, top_n=10, threshold=4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation of Advanced-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Size: 385\n",
      "MAE: 1.1128\n",
      "MSE: 2.1326\n",
      "RMSE: 1.4603\n",
      "Precision: 0.6535\n",
      "Average Hit Rate: 0.6382666966643713\n"
     ]
    }
   ],
   "source": [
    "mae, mse, rmse, precision, avg_hit_rate = evaluate_recommender(df_ratings, recommender_advanced, sample_movie_ids, top_n=10, threshold=4.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advanced model outperforms the baseline model on all metrics. It has lower MAE, MSE, and RMSE values, implying that its recommendations are, on average, closer to ideal ratings and less prone to large errors. Its higher precision and average hit rate indicate that it is more effective at recommending movies that users are likely to rate highly (4.0 or higher), demonstrating a better understanding and matching of user preferences. In short, depending on the evaluation method used, the advanced model provides more accurate and user-aligned recommendations than the baseline model, making it the better option for increasing user satisfaction with the recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Rating Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    166444.000000\n",
      "mean        149.288073\n",
      "std         248.021364\n",
      "min          20.000000\n",
      "25%          35.000000\n",
      "50%          69.000000\n",
      "75%         158.000000\n",
      "max       18276.000000\n",
      "Name: count, dtype: float64\n",
      "count    45028.000000\n",
      "mean       551.836724\n",
      "std       2869.798512\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          8.000000\n",
      "75%         68.000000\n",
      "max      82895.000000\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ratings_per_user = df_ratings[\"userId\"].value_counts()\n",
    "ratings_per_movie = df_ratings[\"movieId\"].value_counts()\n",
    "\n",
    "print(ratings_per_user.describe())\n",
    "print(ratings_per_movie.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    166317.000000\n",
      "mean        148.571679\n",
      "std         239.911174\n",
      "min          20.000000\n",
      "25%          35.000000\n",
      "50%          69.000000\n",
      "75%         158.000000\n",
      "max        9503.000000\n",
      "dtype: float64\n",
      "count    16705.000000\n",
      "mean      1479.197606\n",
      "std       4563.793861\n",
      "min         20.000000\n",
      "25%         48.000000\n",
      "50%        163.000000\n",
      "75%        794.000000\n",
      "max      82877.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ratings_count_per_movie = df_ratings.groupby('movieId').size()\n",
    "movies_with_enough_ratings = ratings_count_per_movie[ratings_count_per_movie >= 20].index\n",
    "prelim_df_ratings_filtered = df_ratings[df_ratings['movieId'].isin(movies_with_enough_ratings)]\n",
    "\n",
    "ratings_count_per_user = prelim_df_ratings_filtered.groupby('userId').size()\n",
    "users_with_enough_ratings = ratings_count_per_user[ratings_count_per_user >= 20].index\n",
    "df_ratings_filtered_final = prelim_df_ratings_filtered[prelim_df_ratings_filtered['userId'].isin(users_with_enough_ratings)]\n",
    "\n",
    "final_ratings_count_per_movie = df_ratings_filtered_final.groupby('movieId').size()\n",
    "final_movies_with_enough_ratings = final_ratings_count_per_movie[final_ratings_count_per_movie >= 20].index\n",
    "df_ratings_filtered_final = df_ratings_filtered_final[df_ratings_filtered_final['movieId'].isin(final_movies_with_enough_ratings)]\n",
    "\n",
    "print(df_ratings_filtered_final.groupby('userId').size().describe())\n",
    "print(df_ratings_filtered_final.groupby('movieId').size().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1235500 entries, 14910339 to 23314789\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count    Dtype         \n",
      "---  ------            --------------    -----         \n",
      " 0   userId            1235500 non-null  int64         \n",
      " 1   movieId           1235500 non-null  int64         \n",
      " 2   rating            1235500 non-null  Float64       \n",
      " 3   timestamp         1235500 non-null  datetime64[ns]\n",
      " 4   user_mean_rating  1235500 non-null  Float64       \n",
      " 5   liked_by_user     1235500 non-null  boolean       \n",
      "dtypes: Float64(2), boolean(1), datetime64[ns](1), int64(2)\n",
      "memory usage: 61.3 MB\n"
     ]
    }
   ],
   "source": [
    "df_ratings_subset = df_ratings_filtered_final.sample(frac=0.05, random_state=42)\n",
    "df_ratings_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9130  0.9133  0.9135  0.9132  0.9129  0.9132  0.0002  \n",
      "MAE (testset)     0.7031  0.7028  0.7036  0.7036  0.7034  0.7033  0.0003  \n",
      "Fit time          9.91    9.58    10.30   9.77    9.89    9.89    0.24    \n",
      "Test time         1.11    1.07    1.12    1.41    1.33    1.21    0.14    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.91303477, 0.91332888, 0.91352622, 0.91320278, 0.91292555]),\n",
       " 'test_mae': array([0.70313489, 0.7028378 , 0.70359434, 0.70358235, 0.70335566]),\n",
       " 'fit_time': (9.909661293029785,\n",
       "  9.575968027114868,\n",
       "  10.30473780632019,\n",
       "  9.768281936645508,\n",
       "  9.891952991485596),\n",
       " 'test_time': (1.1085481643676758,\n",
       "  1.0685420036315918,\n",
       "  1.11647629737854,\n",
       "  1.4074289798736572,\n",
       "  1.3325819969177246)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "\n",
    "# Prepare the data for Surprise\n",
    "data = Dataset.load_from_df(df_ratings_subset[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Initialize the SVD algorithm\n",
    "svd = SVD()\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_validate(svd, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO GILIAN: Matrix geben lassen:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a mean Root Mean Sqaure Error of 0.95 approx which is more than good enough for our case. Let us now train on our dataset and arrive at predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x3ae7a0190>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset = data.build_full_trainset()\n",
    "svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=2, iid=150, r_ui=None, est=4.232214969794782, details={'was_impossible': False})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.predict(2, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE score obtained:  0.9041399444694408\n",
      "Best parameters:  {'n_factors': 50, 'n_epochs': 20, 'lr_all': 0.005, 'reg_all': 0.05}\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_factors': [50, 100],  # Number of factors\n",
    "    'n_epochs': [20],        # Number of iterations\n",
    "    'lr_all': [0.005, 0.01], # Learning rate\n",
    "    'reg_all': [0.02, 0.05]  # Regularization term\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3, n_jobs=-1)\n",
    "\n",
    "gs.fit(data)\n",
    "\n",
    "print(\"Best RMSE score obtained: \", gs.best_score['rmse'])\n",
    "print(\"Best parameters: \", gs.best_params['rmse'])\n",
    "\n",
    "optimized_svd = gs.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> intializing optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_svd = SVD(n_factors=50, n_epochs=20, lr_all=0.005, reg_all=0.05)\n",
    "\n",
    "reader = Reader(rating_scale=(0.5, 5))  \n",
    "data = Dataset.load_from_df(df_ratings_subset[['userId', 'movieId', 'rating']], reader)\n",
    "trainset = data.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x581b81290>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_svd.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.973394488110365\n"
     ]
    }
   ],
   "source": [
    "prediction = optimized_svd.predict(uid=2, iid=3114)\n",
    "print(prediction.est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_model(movie_id, user_id, top_n, svd_model):\n",
    "    # Step 1: Get top N content-based recommendations\n",
    "    content_recs = recommender_base.recommend(movie_id, top_n)\n",
    "\n",
    "    content_recs['movieId'] = content_recs['movieId'].astype(int)\n",
    "\n",
    "    # Step 2: Apply SVD to predict ratings for the top N movies\n",
    "    content_recs['predicted_rating'] = content_recs['movieId'].apply(\n",
    "        lambda x: svd_model.predict(user_id, x).est\n",
    "    )\n",
    "    \n",
    "    # Step 3: Sort recommendations by predicted ratings, then by cosine similarity\n",
    "    final_recs = content_recs.sort_values(\n",
    "        by=['predicted_rating', 'cosine_similarity'], ascending=[False, False]\n",
    "    )\n",
    "    \n",
    "    final_recs = final_recs[['movieId', 'title', 'cosine_similarity', 'predicted_rating']]\n",
    "\n",
    "    return final_recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>predicted_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12007</th>\n",
       "      <td>78499</td>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>0.417211</td>\n",
       "      <td>4.015826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>3114</td>\n",
       "      <td>Toy Story 2</td>\n",
       "      <td>0.498092</td>\n",
       "      <td>3.799826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12339</th>\n",
       "      <td>83219</td>\n",
       "      <td>The Pixar Story</td>\n",
       "      <td>0.178043</td>\n",
       "      <td>3.752612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>7987</td>\n",
       "      <td>Dolls</td>\n",
       "      <td>0.180138</td>\n",
       "      <td>3.623393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9645</th>\n",
       "      <td>46948</td>\n",
       "      <td>Monster House</td>\n",
       "      <td>0.144818</td>\n",
       "      <td>3.472350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>1920</td>\n",
       "      <td>Small Soldiers</td>\n",
       "      <td>0.216866</td>\n",
       "      <td>2.875540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>1991</td>\n",
       "      <td>Child's Play</td>\n",
       "      <td>0.151260</td>\n",
       "      <td>2.797392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>2253</td>\n",
       "      <td>Toys</td>\n",
       "      <td>0.186901</td>\n",
       "      <td>2.783716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>1993</td>\n",
       "      <td>Child's Play 3</td>\n",
       "      <td>0.143198</td>\n",
       "      <td>2.366231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>1707</td>\n",
       "      <td>Home Alone 3</td>\n",
       "      <td>0.163932</td>\n",
       "      <td>2.008950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       movieId            title  cosine_similarity  predicted_rating\n",
       "12007    78499      Toy Story 3           0.417211          4.015826\n",
       "2874      3114      Toy Story 2           0.498092          3.799826\n",
       "12339    83219  The Pixar Story           0.178043          3.752612\n",
       "7112      7987            Dolls           0.180138          3.623393\n",
       "9645     46948    Monster House           0.144818          3.472350\n",
       "1722      1920   Small Soldiers           0.216866          2.875540\n",
       "1793      1991     Child's Play           0.151260          2.797392\n",
       "2048      2253             Toys           0.186901          2.783716\n",
       "1795      1993   Child's Play 3           0.143198          2.366231\n",
       "1552      1707     Home Alone 3           0.163932          2.008950"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hybrid_model(1, 1, 10, optimized_svd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
