{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-29T16:20:48.580231Z",
     "start_time": "2024-03-29T16:20:48.456992Z"
    }
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Collaborative Filtering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f3f1ed81e5340dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Collaborative filtering is a method of making automatic predictions (filtering) about the interests of a user by collecting preferences from many users (collaborating). The underlying assumption of the collaborative filtering approach is that if a person A has the same opinion as a person B on an issue, A is more likely to have B's opinion on a different issue than that of a randomly chosen person.\n",
    "\n",
    "There are two types of collaborative filtering: user-based and item-based. User-based collaborative filtering is based on the similarity between users and item-based collaborative filtering is based on the similarity between items.\n",
    "\n",
    "There are also two types of collaborative filtering algorithms: memory-based and model-based. Memory-based algorithms are based on statistical techniques and model-based algorithms are based on machine learning techniques. In this notebook, we will use model-based algorithms because they can scale with the number of users and items aligning with our goal of building a recommender system for a large user application."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4622d2a2241596f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Item-based Collaborative Filtering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4e8fea516d50400"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's start with an item-based collaborative filtering algorithm. Item-based collaborative filtering is often preferred over user-based collaborative filtering as it tend to perform better when there are many items and fewer users.\n",
    "\n",
    " We will calculate the similarity between items based on the ratings users have given to those items. We will use the cosine similarity to calculate the similarity between items. \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21248191d2e61fc8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_merged = pd.read_pickle('data/df_movies_cleaned.pkl')\n",
    "df_ratings = pd.read_pickle('data/df_ratings_cleaned.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T16:20:50.007923Z",
     "start_time": "2024-03-29T16:20:49.558722Z"
    }
   },
   "id": "33512e045660dbaf",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24848104 entries, 0 to 24848103\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   userId            int64         \n",
      " 1   movieId           int64         \n",
      " 2   rating            Float64       \n",
      " 3   timestamp         datetime64[ns]\n",
      " 4   user_mean_rating  Float64       \n",
      " 5   liked_by_user     boolean       \n",
      "dtypes: Float64(2), boolean(1), datetime64[ns](1), int64(2)\n",
      "memory usage: 1.0 GB\n"
     ]
    }
   ],
   "source": [
    "df_ratings.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T16:20:50.012807Z",
     "start_time": "2024-03-29T16:20:50.008880Z"
    }
   },
   "id": "1a37f4ffff215770",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "             userId       movieId      rating                      timestamp  \\\ncount  2.484810e+07  2.484810e+07  24848104.0                       24848104   \nmean   1.350036e+05  1.621173e+04    3.528737  2007-02-21 23:13:44.095164416   \nmin    1.000000e+00  1.000000e+00         0.5            1995-01-09 11:46:44   \n25%    6.712600e+04  1.088000e+03         3.0            2001-06-09 05:22:35   \n50%    1.351340e+05  2.670000e+03         3.5     2006-06-16 19:53:25.500000   \n75%    2.026420e+05  6.711000e+03         4.0  2013-02-19 17:38:24.249999872   \nmax    2.708960e+05  1.762750e+05         5.0            2017-08-04 06:57:50   \nstd    7.817512e+04  3.135802e+04    1.060048                            NaN   \n\n       user_mean_rating  \ncount        24848104.0  \nmean           3.528737  \nmin                 0.5  \n25%              3.2516  \n50%                3.55  \n75%            3.836879  \nmax                 5.0  \nstd             0.46693  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n      <th>timestamp</th>\n      <th>user_mean_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>2.484810e+07</td>\n      <td>2.484810e+07</td>\n      <td>24848104.0</td>\n      <td>24848104</td>\n      <td>24848104.0</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.350036e+05</td>\n      <td>1.621173e+04</td>\n      <td>3.528737</td>\n      <td>2007-02-21 23:13:44.095164416</td>\n      <td>3.528737</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>0.5</td>\n      <td>1995-01-09 11:46:44</td>\n      <td>0.5</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>6.712600e+04</td>\n      <td>1.088000e+03</td>\n      <td>3.0</td>\n      <td>2001-06-09 05:22:35</td>\n      <td>3.2516</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1.351340e+05</td>\n      <td>2.670000e+03</td>\n      <td>3.5</td>\n      <td>2006-06-16 19:53:25.500000</td>\n      <td>3.55</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.026420e+05</td>\n      <td>6.711000e+03</td>\n      <td>4.0</td>\n      <td>2013-02-19 17:38:24.249999872</td>\n      <td>3.836879</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.708960e+05</td>\n      <td>1.762750e+05</td>\n      <td>5.0</td>\n      <td>2017-08-04 06:57:50</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>7.817512e+04</td>\n      <td>3.135802e+04</td>\n      <td>1.060048</td>\n      <td>NaN</td>\n      <td>0.46693</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T16:38:24.708936Z",
     "start_time": "2024-03-29T16:38:21.196554Z"
    }
   },
   "id": "d4851b0a6f34b61d",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "To safe computational time, we will use a subset of the data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "993db599e3f72317"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1270216 entries, 23070950 to 16502857\n",
      "Data columns (total 6 columns):\n",
      " #   Column            Non-Null Count    Dtype         \n",
      "---  ------            --------------    -----         \n",
      " 0   userId            1270216 non-null  int64         \n",
      " 1   movieId           1270216 non-null  int64         \n",
      " 2   rating            1270216 non-null  Float64       \n",
      " 3   timestamp         1270216 non-null  datetime64[ns]\n",
      " 4   user_mean_rating  1270216 non-null  Float64       \n",
      " 5   liked_by_user     1270216 non-null  boolean       \n",
      "dtypes: Float64(2), boolean(1), datetime64[ns](1), int64(2)\n",
      "memory usage: 63.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_ratings['timestamp'] = pd.to_datetime(df_ratings['timestamp'])\n",
    "df_ratings = df_ratings.sort_values('timestamp')\n",
    "df_ratings_subset = df_ratings[df_ratings['timestamp'] > '2017-01-01']\n",
    "df_ratings_subset.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T16:20:54.133705Z",
     "start_time": "2024-03-29T16:20:51.789619Z"
    }
   },
   "id": "48f2debee7e5e141",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movieId    1         2         3         4         5         6         7       \\\n",
      "movieId                                                                         \n",
      "1        1.000000  0.291622  0.104701  0.041914  0.137984  0.192833  0.083149   \n",
      "2        0.291622  1.000000  0.137777  0.032426  0.167501  0.170788  0.118674   \n",
      "3        0.104701  0.137777  1.000000  0.094457  0.272469  0.137315  0.150091   \n",
      "4        0.041914  0.032426  0.094457  1.000000  0.072964  0.042718  0.024702   \n",
      "5        0.137984  0.167501  0.272469  0.072964  1.000000  0.072802  0.205986   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "176267   0.025938  0.033563  0.000000  0.000000  0.000000  0.000000  0.110065   \n",
      "176269   0.000000  0.039157  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "176271   0.019454  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "176273   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "176275   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "movieId    8         9         10      ...  176253    176255    176257  \\\n",
      "movieId                                ...                               \n",
      "1        0.064074  0.035591  0.199312  ...     0.0  0.000000  0.025938   \n",
      "2        0.132437  0.070944  0.180346  ...     0.0  0.033563  0.033563   \n",
      "3        0.096850  0.117877  0.148216  ...     0.0  0.000000  0.000000   \n",
      "4        0.060224  0.006363  0.023224  ...     0.0  0.000000  0.000000   \n",
      "5        0.096673  0.017023  0.101469  ...     0.0  0.000000  0.000000   \n",
      "...           ...       ...       ...  ...     ...       ...       ...   \n",
      "176267   0.000000  0.000000  0.000000  ...     0.0  0.000000  1.000000   \n",
      "176269   0.000000  0.000000  0.000000  ...     0.0  0.000000  0.000000   \n",
      "176271   0.000000  0.000000  0.000000  ...     0.0  0.000000  0.000000   \n",
      "176273   0.000000  0.000000  0.000000  ...     0.0  0.000000  0.000000   \n",
      "176275   0.000000  0.000000  0.000000  ...     0.0  0.000000  0.000000   \n",
      "\n",
      "movieId    176259    176263    176267    176269    176271  176273  176275  \n",
      "movieId                                                                    \n",
      "1        0.025938  0.025938  0.025938  0.000000  0.019454     0.0     0.0  \n",
      "2        0.033563  0.033563  0.033563  0.039157  0.000000     0.0     0.0  \n",
      "3        0.000000  0.000000  0.000000  0.000000  0.000000     0.0     0.0  \n",
      "4        0.000000  0.000000  0.000000  0.000000  0.000000     0.0     0.0  \n",
      "5        0.000000  0.000000  0.000000  0.000000  0.000000     0.0     0.0  \n",
      "...           ...       ...       ...       ...       ...     ...     ...  \n",
      "176267   1.000000  1.000000  1.000000  0.000000  0.000000     0.0     0.0  \n",
      "176269   0.000000  0.000000  0.000000  1.000000  0.000000     0.0     0.0  \n",
      "176271   0.000000  0.000000  0.000000  0.000000  1.000000     0.0     0.0  \n",
      "176273   0.000000  0.000000  0.000000  0.000000  0.000000     1.0     0.0  \n",
      "176275   0.000000  0.000000  0.000000  0.000000  0.000000     0.0     1.0  \n",
      "\n",
      "[27856 rows x 27856 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 27856 entries, 1 to 176275\n",
      "Columns: 27856 entries, 1 to 176275\n",
      "dtypes: float64(27856)\n",
      "memory usage: 5.8 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Train/Test Split\n",
    "train_data, test_data = train_test_split(df_ratings_subset, test_size=0.2, random_state=42)\n",
    "\n",
    "# User-Item Matrix for Training\n",
    "user_item_matrix_train = train_data.pivot_table(index='userId', columns='movieId', values='rating')\n",
    "\n",
    "# Item-Item Similarity Matrix\n",
    "item_similarity = cosine_similarity(user_item_matrix_train.fillna(0).T)\n",
    "item_similarity_df = pd.DataFrame(item_similarity, index=user_item_matrix_train.columns, columns=user_item_matrix_train.columns)\n",
    "\n",
    "print(item_similarity_df)\n",
    "print(item_similarity_df.info())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T16:47:54.656916Z",
     "start_time": "2024-03-29T16:46:47.779733Z"
    }
   },
   "id": "974bf9e6816ac6d2",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's use Singular Value Decomposition (SVD) on our user-item ratings matrix. SVD helps in extracting latent factors that explain observed ratings, efficiently reducing data dimensionality while preserving essential information. This significantly speeds up calculations, making the process of predicting ratings more efficient, especially when dealing with large dataset like ours. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e408f10ab34450d1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.904032531436712\n"
     ]
    }
   ],
   "source": [
    "user_item_matrix_train = user_item_matrix_train.fillna(0).astype(float)\n",
    "mean_user_rating = user_item_matrix_train.mean(axis=1)\n",
    "R_demeaned = user_item_matrix_train.sub(mean_user_rating, axis='index')\n",
    "\n",
    "R_demeaned_matrix = R_demeaned.values\n",
    "\n",
    "# SVD \n",
    "from scipy.sparse.linalg import svds\n",
    "U, sigma, Vt = svds(R_demeaned_matrix, k=50)  \n",
    "\n",
    "sigma_matrix = np.diag(sigma)\n",
    "all_user_predicted_ratings = np.dot(np.dot(U, sigma_matrix), Vt) + mean_user_rating.values.reshape(-1, 1)\n",
    "\n",
    "preds_df = pd.DataFrame(all_user_predicted_ratings, index=user_item_matrix_train.index, columns=user_item_matrix_train.columns)\n",
    "\n",
    "actual = []\n",
    "predicted = []\n",
    "\n",
    "for index, row in test_data.iterrows():\n",
    "    user_id = row['userId']\n",
    "    movie_id = row['movieId']\n",
    "    if user_id in preds_df.index and movie_id in preds_df.columns:\n",
    "        actual_rating = row['rating']\n",
    "        predicted_rating = preds_df.loc[user_id, movie_id]\n",
    "\n",
    "        actual.append(actual_rating)\n",
    "        predicted.append(predicted_rating)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(actual, predicted))\n",
    "print(f'RMSE: {rmse}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-29T16:46:22.208845Z",
     "start_time": "2024-03-29T16:45:51.588688Z"
    }
   },
   "id": "31a95f09911cedcb",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "Given a 1-to-5 scale, an RMSE of 2.904 is relatively high, indicating that the predictions can be quite far off from the actual ratings. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b02e169b7e20aa1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b1499220e068e4c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
