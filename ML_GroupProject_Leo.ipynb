{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Movie Recommender Systems - DreamStream (Part 2)\n",
    "### Enhancing Movie Recommendations with Deep Learning\n",
    "\n",
    "Benedikt Tremmel (60253) \n",
    "\n",
    "Leonardo Heinemann (60384) \n",
    "\n",
    "Maximilian Schön (50163) \n",
    "\n",
    "Gilian Dustin Wagner (58029) \n",
    "\n",
    "Malte Nicolas Haupt (58733) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f4b7920fb74c04f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. **Introduction**\n",
    "    1.1. Overview and Business Case\n",
    "    1.2. Imports\n",
    "   .....\n",
    "TO BE FINISHED"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52d30bdc7c496c4a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Introduction"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5978ae1b40e7fba9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Overview and Business Case\n",
    "\n",
    "DreamStream is an emerging streaming platform that offers a wide range of movies and TV shows to its users. While DreamStream has been successful in attracting new users, it faces a significant challenge in retaining them. The platform's user retention rate has been declining, primarily due to users' dissatisfaction with the movie recommendations provided. DreamStream's existing recommendation system, based on simple popularity metrics, fails to deliver personalized and relevant recommendations to its users. This lack of personalization leads to user frustration and disengagement, ultimately resulting in churn.\n",
    "\n",
    "\n",
    "##### Short Recap\n",
    "\n",
    "In Part 1 of this project, we focused on addressing DreamStream's user retention challenge by revamping their movie recommendation system using traditional machine learning techniques. We built models based on content-based filtering and collaborative filtering aiming to provide more personalized and relevant movie recommendations. Utilizing a dataset of 45,000 movies and 26 million ratings, our initial efforts helped improving recommendation accuracy. While the initial models provided a foundation, there remains a significant opportunity to leverage more sophisticated technologies to refine recommendation accuracy and personalization. This phase of the project aims to build on the power of deep learning to achieve these objectives, focusing on collaborative filtering and content-based approaches with neural networks.\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ffe28cf72a271f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Why Deep Learning?\n",
    "\n",
    "While traditional machine learning techniques have laid a solid foundation for recommendation systems, they often fall short when it comes to handling complex user behaviors and large-scale data dynamically. Deep learning offers significant advancements in this area, primarily due to its ability to model intricate patterns and interactions within large datasets without extensive feature engineering. Neural networks, in particular, can learn to represent both users and items in a shared latent space, enhancing the system's ability to predict preferences accurately. With NLP techniques, deep learning can also extract valuable information from unstructured data like movie descriptions, enabling more context-aware recommendations. This capability is crucial for DreamStream as it strives to further enhance user engagement and reduce churn by making even more precise and contextually relevant recommendations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fcdb7ed0c7d6cb4d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Model Types\n",
    "\n",
    "HIER BULLET POINT LISTE DER GENUTZEN MODELLE zur übersicht und warum welches model (mit bezug auf business case)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a25a92fffd7519a7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Objectives\n",
    "\n",
    "\n",
    "BITTE ÄNDERN/ANPASSEN, DASS HIER IST NUR EIN VORSCHLAG\n",
    "\n",
    "1. **Improve Recommendation Accuracy**: Develop deep learning models that can predict user preferences more accurately than traditional machine learning models.\n",
    "2. **Leverage Unstructured Data**: Utilize NLP techniques to extract valuable information from unstructured data like movie descriptions to enhance recommendation relevance.\n",
    "3. **Enhance Personalization**: Utilize neural networks to create more personalized recommendations based on user preferences and behavior.\n",
    "4. **Scale Recommendation System**: Build models that can handle large-scale data dynamically and adapt to changing user preferences over time. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91d142c8f4f7d369"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Part 2: Methodology and Approach\n",
    "\n",
    "Part 2 of the project will build on the foundations laid in Part 1, with a primary focus on model development. We will follow the CRISP-DM methodology, but certain stages like exploratory data analysis (EDA) and initial data preparation will be skipped, as they were already covered in Part 1 (please see the appendix for reference).\n",
    "\n",
    "These steps, however, remain critical for Part 2 of the project. Specifically, the EDA provides necessary groundwork for feature selection and offers initial insights into data quality, distribution, and potential biases. Part 2 leverages these insights, allowing us to focus on more complex aspects of model architecture and optimization without re-evaluating the foundational data characteristics. This continuity ensures efficiency and builds on our understanding of the dataset, enabling a more targeted approach in refining the recommendation algorithms with deep learning.\n",
    "\n",
    "The original dataset of 45,000 movies and 26 million ratings can be found [here](https://www.kaggle.com/datasets/rounakbanik/the-movies-dataset/data). For Part 2, we will use a reduced subset (down to 3,000,000 ratings) of the preprocessed version of the dataset to reduce computational time.\n",
    "\n",
    "Additional preprocessing steps tailored for deep learning applications will be implemented prior to model development. These will include critical tasks such as tokenization, normalization, and padding of text data to ensure compatibility with neural network architectures. We will also present the best models for both collaborative and content-based filtering from Part 1 and compare them with the deep learning models.\n",
    "The primary metric utilized will be precision, which measures the proportion of relevant recommendations among the total recommendations made. This metric allows us to evaluate the models' ability to accurately predict user preferences and provide relevant movie recommendations. Additional metrics such as the RMSE will also be considered to provide a comprehensive evaluation of the models' performance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ddc6e0575e34731"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Imports\n",
    "\n",
    "The project will be implemented using Python and the following libraries:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7354037b286c82f0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1bb25d8e83c8753e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
